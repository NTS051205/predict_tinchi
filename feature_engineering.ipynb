{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Engineering - Last Dance\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Seed cố định để kết quả reproducible\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "DATA_DIR = 'data'\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Đã định nghĩa create_features_y2plus và FEAT_COLS_Y2PLUS (cho Y2-Y6)\n",
            "NUMERIC_FEATURES: ['Load_Ratio', 'Prev_CPA', 'Prev_GPA', 'History_Completion_Rate', 'History_Fail_Credits', 'Semester_No', 'Gap_Score', 'is_Covid']\n",
            "CATEGORICAL_FEATURES (Y2+): ['TOHOP_GROUP', 'PTXT_GROUP']\n",
            "\n",
            "✓ Loaded final_combined_cleaned: (105726, 15)\n",
            "✓ Loaded test_Y1_Sem1: (4326, 11)\n",
            "✓ Loaded test_con_lai: (12176, 11)\n",
            "✓ Loaded train_year_1: (25027, 19)\n",
            "✓ Loaded train_year_2: (23154, 19)\n",
            "✓ Loaded train_year_3: (20940, 19)\n",
            "✓ Loaded train_year_4: (13848, 19)\n",
            "✓ Loaded train_year_5: (6822, 19)\n",
            "✓ Loaded train_year_6: (791, 19)\n",
            "✓ Loaded valid.csv: 15144 rows → tách thành 6 nhóm năm\n",
            "\n",
            "Tổng kết:\n",
            " - Combined cleaned: ✓\n",
            " - Test files: 1 files (có thể bao gồm Y7)\n",
            " - Train files: 6/6 files\n",
            " - Valid: 1 file → 6 nhóm năm\n"
          ]
        }
      ],
      "source": [
        "# === Định nghĩa hàm create_features cho Y1 (giữ nguyên như cũ) ===\n",
        "\n",
        "def create_features_y1_sem1(df_in):\n",
        "    \"\"\"Hàm tạo features cho Y1 Sem1: Rank_In_Major, Gap_Score, TOHOP_GROUP, PTXT_GROUP\"\"\"\n",
        "    df = df_in.copy()\n",
        "    \n",
        "    # Gap_Score\n",
        "    df['Gap_Score'] = (df['DIEM_TRUNGTUYEN'].fillna(0) - df['DIEM_CHUAN'].fillna(0))\n",
        "    \n",
        "    # Rank_In_Major: Percentile rank trong cùng khóa + tổ hợp (chỉ Y1 Sem1)\n",
        "    df['Rank_In_Major'] = 0.0\n",
        "    if 'NAM_TUYENSINH' in df.columns and 'TOHOP_XT' in df.columns:\n",
        "        fresh_df = df.copy()\n",
        "        fresh_df['_n'] = fresh_df['NAM_TUYENSINH'].astype(str).str.strip()\n",
        "        fresh_df['_t'] = fresh_df['TOHOP_XT'].astype(str).str.strip()\n",
        "        r = fresh_df.groupby(['_n', '_t'])['DIEM_TRUNGTUYEN'].fillna(0).rank(pct=True)\n",
        "        df['Rank_In_Major'] = r.fillna(0.5)\n",
        "    \n",
        "    # TOHOP_GROUP: Khoa học tự nhiên (A,B), Xã hội (C), Khác (D,...)\n",
        "    if 'TOHOP_XT' in df.columns:\n",
        "        _first = df['TOHOP_XT'].astype(str).str.strip().str.upper().str[0]\n",
        "        df['TOHOP_GROUP'] = np.where(_first.isin(['A', 'B']), 'KHTN', \n",
        "                                     np.where(_first == 'C', 'XH', 'Khac'))\n",
        "    else:\n",
        "        df['TOHOP_GROUP'] = 'Khac'\n",
        "    \n",
        "    # PTXT_GROUP: Giữ nguyên PTXT nếu là giá trị phổ biến, còn lại gán \"1\"\n",
        "    if 'PTXT' in df.columns:\n",
        "        df['PTXT_GROUP'] = df['PTXT'].astype(str)\n",
        "    else:\n",
        "        df['PTXT_GROUP'] = '1'\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Feature cho Y1: dùng FEATS_Y1\n",
        "FEATS_Y1 = ['Rank_In_Major', 'Gap_Score', 'TOHOP_GROUP', 'PTXT_GROUP']\n",
        "\n",
        "# === Định nghĩa hàm create_features cho Y2+ (giống train_by_year_predict.ipynb) ===\n",
        "\n",
        "def create_features_y2plus(df_in):\n",
        "    \"\"\"Hàm chung cho Train và Test. Xử lý Lag, History, Load_Ratio, is_Covid, Gap_Score, SV năm 1 kỳ 1.\"\"\"\n",
        "    df = df_in.copy()\n",
        "    \n",
        "    # Chuẩn hóa cột\n",
        "    if 'Hoc_Ky' not in df.columns and 'HOC_KY' in df.columns:\n",
        "        df['Hoc_Ky'] = df['HOC_KY']\n",
        "    if 'Nam_Hoc' not in df.columns and 'NAM_HOC' in df.columns:\n",
        "        df['Nam_Hoc'] = df['NAM_HOC']\n",
        "    df['Nam_Hoc'] = df['Nam_Hoc'].astype(str)\n",
        "    df['_year'] = df['Nam_Hoc'].str.split('-').str[0].astype(float)\n",
        "    df['_hk'] = pd.to_numeric(df['Hoc_Ky'], errors='coerce').fillna(1).astype(int)\n",
        "    df = df.sort_values(['MA_SO_SV', '_year', '_hk']).reset_index(drop=True)\n",
        "\n",
        "    # Gap_Score, is_Covid\n",
        "    df['Gap_Score'] = (df['DIEM_TRUNGTUYEN'].fillna(0) - df['DIEM_CHUAN'].fillna(0))\n",
        "    df['is_Covid'] = df['Nam_Hoc'].isin(['2020-2021', '2021-2022']).astype(int)\n",
        "\n",
        "    grp = df.groupby('MA_SO_SV')\n",
        "    \n",
        "    # Lag: Prev_GPA, Prev_CPA (shift 1 kỳ)\n",
        "    df['Prev_CPA'] = grp['CPA'].shift(1)\n",
        "    df['Prev_GPA'] = grp['GPA'].shift(1)\n",
        "    \n",
        "    # History: History_Completion_Rate, History_Fail_Credits, Avg_History_Load\n",
        "    cum_reg = grp['TC_DANGKY'].cumsum().shift(1)\n",
        "    cum_comp = grp['TC_HOANTHANH'].fillna(0).cumsum().shift(1)\n",
        "    df['History_Completion_Rate'] = np.where(cum_reg > 0, cum_comp / cum_reg, 0)\n",
        "    df['_fail'] = (df['TC_DANGKY'].fillna(0) - df['TC_HOANTHANH'].fillna(0)).clip(lower=0)\n",
        "    df['History_Fail_Credits'] = np.maximum(0, grp['_fail'].cumsum().shift(1))\n",
        "    df['Semester_No'] = grp.cumcount() + 1\n",
        "    avg_load = grp['TC_HOANTHANH'].fillna(0).cumsum().shift(1) / np.maximum(df['Semester_No'] - 1, 1)\n",
        "    avg_load = np.where(avg_load <= 0, df['TC_DANGKY'].fillna(0), avg_load)\n",
        "    df['Avg_History_Load'] = avg_load\n",
        "    df['Load_Ratio'] = np.where(avg_load > 0, df['TC_DANGKY'] / avg_load, 1.0)\n",
        "\n",
        "    # Xử lý SV năm 1 kỳ 1: Prev_CPA/Prev_GPA = (DIEM_TRUNGTUYEN/30)*4, History=1, Load_Ratio=1\n",
        "    is_fresh = (df['Semester_No'] == 1)\n",
        "    diem_proxy = (df['DIEM_TRUNGTUYEN'].fillna(0) / 30) * 4\n",
        "    df.loc[is_fresh, 'Prev_CPA'] = diem_proxy[is_fresh]\n",
        "    df.loc[is_fresh, 'Prev_GPA'] = diem_proxy[is_fresh]\n",
        "    df.loc[is_fresh, 'History_Completion_Rate'] = 1.0\n",
        "    df.loc[is_fresh, 'History_Fail_Credits'] = 0\n",
        "    df.loc[is_fresh, 'Load_Ratio'] = 1.0\n",
        "\n",
        "    # Y2+: TOHOP_GROUP (KHTN / XH / Khác) và PTXT_GROUP — thay thế TOHOP_XT, PTXT\n",
        "    if 'TOHOP_XT' in df.columns:\n",
        "        _first = df['TOHOP_XT'].astype(str).str.strip().str.upper().str[0]\n",
        "        df['TOHOP_GROUP'] = np.where(_first.isin(['A', 'B']), 'KHTN', np.where(_first == 'C', 'XH', 'Khac'))\n",
        "        df = df.drop(columns=['TOHOP_XT'], errors='ignore')\n",
        "    else:\n",
        "        df['TOHOP_GROUP'] = 'Khac'\n",
        "    if 'PTXT' in df.columns:\n",
        "        df['PTXT_GROUP'] = df['PTXT'].astype(str)\n",
        "        df = df.drop(columns=['PTXT'], errors='ignore')\n",
        "    else:\n",
        "        df['PTXT_GROUP'] = '1'\n",
        "\n",
        "    return df\n",
        "\n",
        "# Định nghĩa feature cho Y2+ (dùng TOHOP_GROUP, PTXT_GROUP như Y1)\n",
        "NUMERIC_FEATURES_Y2PLUS = [\n",
        "    'Load_Ratio', 'Prev_CPA', 'Prev_GPA',\n",
        "    'History_Completion_Rate', 'History_Fail_Credits',\n",
        "    'Semester_No', 'Gap_Score', 'is_Covid'\n",
        "]\n",
        "CATEGORICAL_FEATURES_Y2PLUS = ['TOHOP_GROUP', 'PTXT_GROUP']\n",
        "FEAT_COLS_Y2PLUS = NUMERIC_FEATURES_Y2PLUS + CATEGORICAL_FEATURES_Y2PLUS\n",
        "\n",
        "print(\"Đã định nghĩa create_features_y2plus và FEAT_COLS_Y2PLUS (cho Y2-Y6)\")\n",
        "print(f\"NUMERIC_FEATURES: {NUMERIC_FEATURES_Y2PLUS}\")\n",
        "print(f\"CATEGORICAL_FEATURES (Y2+): {CATEGORICAL_FEATURES_Y2PLUS}\")\n",
        "\n",
        "# Load dữ liệu đã được xử lý từ data_cleaning và data_preprocessing\n",
        "\n",
        "# Load final_combined_cleaned (train + valid)\n",
        "path_final = os.path.join(DATA_DIR, 'final_combined_cleaned.csv')\n",
        "if os.path.exists(path_final):\n",
        "    combined_cleaned = pd.read_csv(path_final)\n",
        "    print(f'\\n✓ Loaded final_combined_cleaned: {combined_cleaned.shape}')\n",
        "else:\n",
        "    combined_cleaned = None\n",
        "    print(f'\\n✗ Chưa tìm thấy {path_final} – hãy chạy data_cleaning và data_preprocessing trước.')\n",
        "test_files = {}\n",
        "# Y1: chỉ cần test_Y1_Sem1.csv\n",
        "path_y1 = os.path.join(DATA_DIR, 'test_Y1_Sem1.csv')\n",
        "if os.path.exists(path_y1):\n",
        "    test_files['Y1_Sem1'] = pd.read_csv(path_y1)\n",
        "    print(f'✓ Loaded test_Y1_Sem1: {test_files[\"Y1_Sem1\"].shape}')\n",
        "else:\n",
        "    print('✗ Chưa tìm thấy test_Y1_Sem1.csv')\n",
        "\n",
        "# Test Y2+: load 1 file test_con_lai.csv (data_preprocessing không lưu test_Y2..Y7 riêng nữa)\n",
        "path_con_lai = os.path.join(DATA_DIR, 'test_con_lai.csv')\n",
        "test_con_lai_df = pd.read_csv(path_con_lai) if os.path.exists(path_con_lai) else None\n",
        "if test_con_lai_df is not None:\n",
        "    print(f'✓ Loaded test_con_lai: {test_con_lai_df.shape}')\n",
        "\n",
        "# Load train files\n",
        "train_files = {}\n",
        "for year in range(1, 7):\n",
        "    path_train = os.path.join(DATA_DIR, f'train_year_{year}.csv')\n",
        "    if os.path.exists(path_train):\n",
        "        train_files[f'Y{year}'] = pd.read_csv(path_train)\n",
        "        print(f'✓ Loaded train_year_{year}: {train_files[f\"Y{year}\"].shape}')\n",
        "\n",
        "# Load valid: 1 file valid.csv (data_preprocessing không chia theo năm), tách theo Year_of_Study thành valid_files\n",
        "valid_files = {}\n",
        "path_valid = os.path.join(DATA_DIR, 'valid.csv')\n",
        "if os.path.exists(path_valid):\n",
        "    valid_df = pd.read_csv(path_valid)\n",
        "    if 'Year_of_Study' not in valid_df.columns and '_year' in valid_df.columns:\n",
        "        valid_df['Year_of_Study'] = (valid_df['_year'] - valid_df['NAM_TUYENSINH'].fillna(valid_df['_year']) + 1).clip(lower=1).fillna(1).astype(int)\n",
        "    if 'Year_of_Study' in valid_df.columns:\n",
        "        for year in range(1, 7):\n",
        "            sub = valid_df[valid_df['Year_of_Study'] == year].copy()\n",
        "            if len(sub) > 0:\n",
        "                valid_files[f'Y{year}'] = sub\n",
        "        print(f'✓ Loaded valid.csv: {len(valid_df)} rows → tách thành {len(valid_files)} nhóm năm')\n",
        "    else:\n",
        "        valid_files['Y1'] = valid_df\n",
        "        print(f'✓ Loaded valid.csv: {len(valid_df)} rows (không có Year_of_Study, coi toàn bộ là Y1)')\n",
        "else:\n",
        "    print('✗ Chưa tìm thấy valid.csv – hãy chạy data_preprocessing trước.')\n",
        "\n",
        "print(f'\\nTổng kết:')\n",
        "print(f' - Combined cleaned: {\"✓\" if combined_cleaned is not None else \"✗\"}')\n",
        "print(f' - Test files: {len(test_files)} files (có thể bao gồm Y7)')\n",
        "print(f' - Train files: {len(train_files)}/{6} files')\n",
        "print(f' - Valid: 1 file → {len(valid_files)} nhóm năm' if valid_files else \" - Valid: chưa load\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## I. Tạo features cho Y1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# I.1 Y1 dùng create_features_y1_sem1 và FEATS_Y1 \n",
        "# Hàm create_features_y1_sem1 đã được định nghĩa ở cell trên"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Đã tạo features cho test Y1: (4326, 15)\n",
            "Các features mới: ['Gap_Score', 'Rank_In_Major', 'TOHOP_GROUP', 'PTXT_GROUP']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/h4/1myh9v5149vfd754lvvkttpw0000gn/T/ipykernel_16500/440256927.py:16: FutureWarning: SeriesGroupBy.fillna is deprecated and will be removed in a future version. Use obj.ffill() or obj.bfill() for forward or backward filling instead. If you want to fill with a single value, use Series.fillna instead\n",
            "  r = fresh_df.groupby(['_n', '_t'])['DIEM_TRUNGTUYEN'].fillna(0).rank(pct=True)\n"
          ]
        }
      ],
      "source": [
        "# I.2 Tạo features cho test Y1 (dùng create_features_y1_sem1)\n",
        "\n",
        "test_y1_feats = None\n",
        "if 'Y1_Sem1' in test_files:\n",
        "    test_y1_raw = test_files['Y1_Sem1'].copy()\n",
        "    test_y1_feats = create_features_y1_sem1(test_y1_raw)\n",
        "    print(f'Đã tạo features cho test Y1: {test_y1_feats.shape}')\n",
        "    new_cols = [c for c in test_y1_feats.columns if c not in test_y1_raw.columns]\n",
        "    print(f'Các features mới: {new_cols[:10]}' if len(new_cols) > 10 else f'Các features mới: {new_cols}')\n",
        "else:\n",
        "    print('Chưa có test_Y1_Sem1, hãy chạy data_preprocessing trước.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/h4/1myh9v5149vfd754lvvkttpw0000gn/T/ipykernel_16500/440256927.py:16: FutureWarning: SeriesGroupBy.fillna is deprecated and will be removed in a future version. Use obj.ffill() or obj.bfill() for forward or backward filling instead. If you want to fill with a single value, use Series.fillna instead\n",
            "  r = fresh_df.groupby(['_n', '_t'])['DIEM_TRUNGTUYEN'].fillna(0).rank(pct=True)\n",
            "/var/folders/h4/1myh9v5149vfd754lvvkttpw0000gn/T/ipykernel_16500/440256927.py:16: FutureWarning: SeriesGroupBy.fillna is deprecated and will be removed in a future version. Use obj.ffill() or obj.bfill() for forward or backward filling instead. If you want to fill with a single value, use Series.fillna instead\n",
            "  r = fresh_df.groupby(['_n', '_t'])['DIEM_TRUNGTUYEN'].fillna(0).rank(pct=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Đã tạo features cho train Y1: (25027, 23)\n",
            "Đã tạo features cho valid Y1: (3504, 23)\n"
          ]
        }
      ],
      "source": [
        "# I.2b Tạo features cho train Y1 và valid Y1 (dùng create_features_y1_sem1)\n",
        "\n",
        "train_y1_feats = None\n",
        "valid_y1_feats = None\n",
        "\n",
        "if 'Y1' in train_files:\n",
        "    train_y1_raw = train_files['Y1'].copy()\n",
        "    train_y1_feats = create_features_y1_sem1(train_y1_raw)\n",
        "    print(f'Đã tạo features cho train Y1: {train_y1_feats.shape}')\n",
        "if 'Y1' in valid_files:\n",
        "    valid_y1_raw = valid_files['Y1'].copy()\n",
        "    valid_y1_feats = create_features_y1_sem1(valid_y1_raw)\n",
        "    print(f'Đã tạo features cho valid Y1: {valid_y1_feats.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PTXT_TOP (10 giá trị phổ biến nhất): ['1', '100', '409', '402', '500', '200']\n",
            "Đã tạo PTXT_GROUP cho train, valid, test Y1\n"
          ]
        }
      ],
      "source": [
        "# I.3 Xử lý PTXT_GROUP cho Y1: Tạo PTXT_TOP từ train data và gán cho train/valid/test\n",
        "\n",
        "# Tính PTXT_TOP từ train Y1 (các giá trị phổ biến nhất)\n",
        "if train_y1_feats is not None and 'PTXT' in train_y1_feats.columns:\n",
        "    ptxt_counts = train_y1_feats['PTXT'].astype(str).value_counts()\n",
        "    PTXT_TOP = ptxt_counts.head(10).index.tolist()\n",
        "    print(f'PTXT_TOP (10 giá trị phổ biến nhất): {PTXT_TOP}')\n",
        "    \n",
        "    # Gán PTXT_GROUP: giữ nguyên nếu trong TOP, còn lại gán \"1\"\n",
        "    for df_name, df_feats in [('train', train_y1_feats), ('valid', valid_y1_feats), ('test', test_y1_feats if 'test_y1_feats' in locals() else None)]:\n",
        "        if df_feats is not None and 'PTXT' in df_feats.columns:\n",
        "            df_feats['PTXT_GROUP'] = df_feats['PTXT'].astype(str)\n",
        "            df_feats.loc[~df_feats['PTXT_GROUP'].isin(PTXT_TOP), 'PTXT_GROUP'] = '1'\n",
        "    print('Đã tạo PTXT_GROUP cho train, valid, test Y1')\n",
        "else:\n",
        "    PTXT_TOP = []\n",
        "    print('⚠ Chưa có train_y1_feats hoặc cột PTXT để tính PTXT_TOP')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Y1 features: (25027, 5)\n",
            "Valid Y1 features: (3504, 5)\n",
            "Test Y1 features: (4326, 5)\n",
            "Features: ['Rank_In_Major', 'Gap_Score', 'TOHOP_GROUP', 'PTXT_GROUP']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MA_SO_SV</th>\n",
              "      <th>Rank_In_Major</th>\n",
              "      <th>Gap_Score</th>\n",
              "      <th>TOHOP_GROUP</th>\n",
              "      <th>PTXT_GROUP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7f9d7b4e7e62</td>\n",
              "      <td>0.955155</td>\n",
              "      <td>5.31</td>\n",
              "      <td>KHTN</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8c9226f36525</td>\n",
              "      <td>0.256241</td>\n",
              "      <td>5.68</td>\n",
              "      <td>Khac</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0b58da4d395d</td>\n",
              "      <td>0.348706</td>\n",
              "      <td>1.24</td>\n",
              "      <td>KHTN</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0e73af55556e</td>\n",
              "      <td>0.953421</td>\n",
              "      <td>4.85</td>\n",
              "      <td>Khac</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c15afd37f75b</td>\n",
              "      <td>0.513870</td>\n",
              "      <td>2.37</td>\n",
              "      <td>KHTN</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       MA_SO_SV  Rank_In_Major  Gap_Score TOHOP_GROUP PTXT_GROUP\n",
              "0  7f9d7b4e7e62       0.955155       5.31        KHTN        100\n",
              "1  8c9226f36525       0.256241       5.68        Khac        100\n",
              "2  0b58da4d395d       0.348706       1.24        KHTN        100\n",
              "3  0e73af55556e       0.953421       4.85        Khac        100\n",
              "4  c15afd37f75b       0.513870       2.37        KHTN        100"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# I.4 Gán features cho Y1 (dùng FEATS_Y1)\n",
        "\n",
        "train_y1_final = None\n",
        "valid_y1_final = None\n",
        "test_y1_final = None\n",
        "\n",
        "if train_y1_feats is not None:\n",
        "    cols = [c for c in FEATS_Y1 if c in train_y1_feats.columns]\n",
        "    train_y1_final = train_y1_feats[['MA_SO_SV'] + cols].copy()\n",
        "    print(f'Train Y1 features: {train_y1_final.shape}')\n",
        "if valid_y1_feats is not None:\n",
        "    cols = [c for c in FEATS_Y1 if c in valid_y1_feats.columns]\n",
        "    valid_y1_final = valid_y1_feats[['MA_SO_SV'] + cols].copy()\n",
        "    print(f'Valid Y1 features: {valid_y1_final.shape}')\n",
        "if test_y1_feats is not None:\n",
        "    cols = [c for c in FEATS_Y1 if c in test_y1_feats.columns]\n",
        "    test_y1_final = test_y1_feats[['MA_SO_SV'] + cols].copy()\n",
        "    print(f'Test Y1 features: {test_y1_final.shape}')\n",
        "    print(f'Features: {cols}')\n",
        "    display(test_y1_final.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Đã lưu train: data/train_Y1_features.csv (25027 rows)\n",
            "Đã lưu test: data/test_Y1_features.csv (4326 rows)\n"
          ]
        }
      ],
      "source": [
        "# I.5 Lưu features cho Y1 (chỉ train và test; valid gộp vào valid_features.csv ở II.2)\n",
        "\n",
        "saved = []\n",
        "if train_y1_final is not None:\n",
        "    p = os.path.join(DATA_DIR, 'train_Y1_features.csv')\n",
        "    train_y1_final.to_csv(p, index=False)\n",
        "    saved.append(f'train: {p} ({len(train_y1_final)} rows)')\n",
        "if test_y1_final is not None:\n",
        "    p = os.path.join(DATA_DIR, 'test_Y1_features.csv')\n",
        "    test_y1_final.to_csv(p, index=False)\n",
        "    saved.append(f'test: {p} ({len(test_y1_final)} rows)')\n",
        "\n",
        "for s in saved:\n",
        "    print(f'Đã lưu {s}')\n",
        "if not saved:\n",
        "    print('Chưa có dữ liệu features để lưu (cần chạy data_preprocessing và lưu valid trước).')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Đã định nghĩa create_features_y2plus và FEAT_COLS_Y2PLUS\n",
            "NUMERIC_FEATURES: ['Load_Ratio', 'Prev_CPA', 'Prev_GPA', 'History_Completion_Rate', 'History_Fail_Credits', 'Semester_No', 'Gap_Score', 'is_Covid']\n",
            "CATEGORICAL_FEATURES (Y2+): ['TOHOP_GROUP', 'PTXT_GROUP']\n"
          ]
        }
      ],
      "source": [
        "# === II.0 Hàm create_features cho Y2+ ===\n",
        "\n",
        "def create_features_y2plus(df_in):\n",
        "    df = df_in.copy()\n",
        "    \n",
        "    # Chuẩn hóa cột\n",
        "    if 'Hoc_Ky' not in df.columns and 'HOC_KY' in df.columns:\n",
        "        df['Hoc_Ky'] = df['HOC_KY']\n",
        "    if 'Nam_Hoc' not in df.columns and 'NAM_HOC' in df.columns:\n",
        "        df['Nam_Hoc'] = df['NAM_HOC']\n",
        "    df['Nam_Hoc'] = df['Nam_Hoc'].astype(str)\n",
        "    df['_year'] = df['Nam_Hoc'].str.split('-').str[0].astype(float)\n",
        "    df['_hk'] = pd.to_numeric(df['Hoc_Ky'], errors='coerce').fillna(1).astype(int)\n",
        "    df = df.sort_values(['MA_SO_SV', '_year', '_hk']).reset_index(drop=True)\n",
        "\n",
        "    # Gap_Score, is_Covid\n",
        "    df['Gap_Score'] = (df['DIEM_TRUNGTUYEN'].fillna(0) - df['DIEM_CHUAN'].fillna(0))\n",
        "    df['is_Covid'] = df['Nam_Hoc'].isin(['2020-2021', '2021-2022']).astype(int)\n",
        "\n",
        "    grp = df.groupby('MA_SO_SV')\n",
        "    \n",
        "    # Lag: Prev_GPA, Prev_CPA (shift 1 kỳ)\n",
        "    df['Prev_CPA'] = grp['CPA'].shift(1)\n",
        "    df['Prev_GPA'] = grp['GPA'].shift(1)\n",
        "    \n",
        "    # History: History_Completion_Rate, History_Fail_Credits, Avg_History_Load\n",
        "    cum_reg = grp['TC_DANGKY'].cumsum().shift(1)\n",
        "    cum_comp = grp['TC_HOANTHANH'].fillna(0).cumsum().shift(1)\n",
        "    df['History_Completion_Rate'] = np.where(cum_reg > 0, cum_comp / cum_reg, 0)\n",
        "    df['_fail'] = (df['TC_DANGKY'].fillna(0) - df['TC_HOANTHANH'].fillna(0)).clip(lower=0)\n",
        "    df['History_Fail_Credits'] = np.maximum(0, grp['_fail'].cumsum().shift(1))\n",
        "    df['Semester_No'] = grp.cumcount() + 1\n",
        "    avg_load = grp['TC_HOANTHANH'].fillna(0).cumsum().shift(1) / np.maximum(df['Semester_No'] - 1, 1)\n",
        "    avg_load = np.where(avg_load <= 0, df['TC_DANGKY'].fillna(0), avg_load)\n",
        "    df['Avg_History_Load'] = avg_load\n",
        "    df['Load_Ratio'] = np.where(avg_load > 0, df['TC_DANGKY'] / avg_load, 1.0)\n",
        "\n",
        "    # Xử lý SV năm 1 kỳ 1: Prev_CPA/Prev_GPA = (DIEM_TRUNGTUYEN/30)*4, History=1, Load_Ratio=1\n",
        "    is_fresh = (df['Semester_No'] == 1)\n",
        "    diem_proxy = (df['DIEM_TRUNGTUYEN'].fillna(0) / 30) * 4\n",
        "    df.loc[is_fresh, 'Prev_CPA'] = diem_proxy[is_fresh]\n",
        "    df.loc[is_fresh, 'Prev_GPA'] = diem_proxy[is_fresh]\n",
        "    df.loc[is_fresh, 'History_Completion_Rate'] = 1.0\n",
        "    df.loc[is_fresh, 'History_Fail_Credits'] = 0\n",
        "    df.loc[is_fresh, 'Load_Ratio'] = 1.0\n",
        "\n",
        "    # Y2+: TOHOP_GROUP (KHTN/XH/Khác), PTXT_GROUP — thay thế TOHOP_XT, PTXT (trùng với cell 2)\n",
        "    if 'TOHOP_XT' in df.columns:\n",
        "        _first = df['TOHOP_XT'].astype(str).str.strip().str.upper().str[0]\n",
        "        df['TOHOP_GROUP'] = np.where(_first.isin(['A', 'B']), 'KHTN', np.where(_first == 'C', 'XH', 'Khac'))\n",
        "        df = df.drop(columns=['TOHOP_XT'], errors='ignore')\n",
        "    else:\n",
        "        df['TOHOP_GROUP'] = 'Khac'\n",
        "    if 'PTXT' in df.columns:\n",
        "        df['PTXT_GROUP'] = df['PTXT'].astype(str)\n",
        "        df = df.drop(columns=['PTXT'], errors='ignore')\n",
        "    else:\n",
        "        df['PTXT_GROUP'] = '1'\n",
        "\n",
        "    return df\n",
        "\n",
        "# Định nghĩa feature cho Y2+ (dùng TOHOP_GROUP, PTXT_GROUP — giống cell 2)\n",
        "NUMERIC_FEATURES_Y2PLUS = [\n",
        "    'Load_Ratio', 'Prev_CPA', 'Prev_GPA',\n",
        "    'History_Completion_Rate', 'History_Fail_Credits',\n",
        "    'Semester_No', 'Gap_Score', 'is_Covid'\n",
        "]\n",
        "CATEGORICAL_FEATURES_Y2PLUS = ['TOHOP_GROUP', 'PTXT_GROUP']\n",
        "FEAT_COLS_Y2PLUS = NUMERIC_FEATURES_Y2PLUS + CATEGORICAL_FEATURES_Y2PLUS\n",
        "\n",
        "print(\"Đã định nghĩa create_features_y2plus và FEAT_COLS_Y2PLUS\")\n",
        "print(f\"NUMERIC_FEATURES: {NUMERIC_FEATURES_Y2PLUS}\")\n",
        "print(f\"CATEGORICAL_FEATURES (Y2+): {CATEGORICAL_FEATURES_Y2PLUS}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## II. Tạo features cho Y2, Y3, Y4, Y5, Y6, Y7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FEATS_Y2_Y7: ['Prev_GPA', 'Prev_CPA', 'Recent_Completion_Rate', 'LongTerm_Completion_Rate', 'is_Covid', 'Semester_No', 'Gap_Semester_Count', 'GPA_Momentum', 'Workload_Risk', 'Record_Gap_Flag', 'Recovery_Potential', 'Heavy_Load_Flag']\n"
          ]
        }
      ],
      "source": [
        "# II.1 (Legacy) FEATS_Y2_Y7 - không dùng; Y2-Y6 dùng FEAT_COLS_Y2PLUS (giống train_by_year)\n",
        "\n",
        "FEATS_Y2_Y7 = [\n",
        "    'Prev_GPA', 'Prev_CPA',\n",
        "    'Recent_Completion_Rate', 'LongTerm_Completion_Rate',\n",
        "    'is_Covid', 'Semester_No', 'Gap_Semester_Count',\n",
        "    'GPA_Momentum', 'Workload_Risk',\n",
        "    'Record_Gap_Flag', 'Recovery_Potential', 'Heavy_Load_Flag',\n",
        "]\n",
        "print('FEATS_Y2_Y7:', FEATS_Y2_Y7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tính features đầy đủ từ final_combined_cleaned (Y2+ dùng create_features_y2plus)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/h4/1myh9v5149vfd754lvvkttpw0000gn/T/ipykernel_16500/3968139960.py:28: FutureWarning: SeriesGroupBy.fillna is deprecated and will be removed in a future version. Use obj.ffill() or obj.bfill() for forward or backward filling instead. If you want to fill with a single value, use Series.fillna instead\n",
            "  cum_comp = grp['TC_HOANTHANH'].fillna(0).cumsum().shift(1)\n",
            "/var/folders/h4/1myh9v5149vfd754lvvkttpw0000gn/T/ipykernel_16500/3968139960.py:33: FutureWarning: SeriesGroupBy.fillna is deprecated and will be removed in a future version. Use obj.ffill() or obj.bfill() for forward or backward filling instead. If you want to fill with a single value, use Series.fillna instead\n",
            "  avg_load = grp['TC_HOANTHANH'].fillna(0).cumsum().shift(1) / np.maximum(df['Semester_No'] - 1, 1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  PTXT_TOP Y2+ (10 giá trị phổ biến): ['1', '100', '409', '500', '3', '402', '5', '200']\n",
            "  Train features: 90582 rows | Valid features: 15144 rows\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/h4/1myh9v5149vfd754lvvkttpw0000gn/T/ipykernel_16500/3968139960.py:28: FutureWarning: SeriesGroupBy.fillna is deprecated and will be removed in a future version. Use obj.ffill() or obj.bfill() for forward or backward filling instead. If you want to fill with a single value, use Series.fillna instead\n",
            "  cum_comp = grp['TC_HOANTHANH'].fillna(0).cumsum().shift(1)\n",
            "/var/folders/h4/1myh9v5149vfd754lvvkttpw0000gn/T/ipykernel_16500/3968139960.py:33: FutureWarning: SeriesGroupBy.fillna is deprecated and will be removed in a future version. Use obj.ffill() or obj.bfill() for forward or backward filling instead. If you want to fill with a single value, use Series.fillna instead\n",
            "  avg_load = grp['TC_HOANTHANH'].fillna(0).cumsum().shift(1) / np.maximum(df['Semester_No'] - 1, 1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Test Y2+ (1 file gộp): data/test_Y2plus_features.csv (12176 rows)\n",
            "Y2 train: data/train_Y2_features.csv (23154 rows)\n",
            "Y3 train: data/train_Y3_features.csv (20940 rows)\n",
            "Y4 train: data/train_Y4_features.csv (13848 rows)\n",
            "Y5 train: data/train_Y5_features.csv (6822 rows)\n",
            "Y6 train: data/train_Y6_features.csv (791 rows)\n",
            "Y7: không có dữ liệu\n",
            "Valid Y1: data/valid_Y1_features.csv (3504 rows)\n",
            "Valid Y2+ (1 file): data/valid_Y2plus_features.csv (11640 rows)\n"
          ]
        }
      ],
      "source": [
        "# II.2 Tạo features: train/valid theo từng năm; test Y2+ một file gộp (có Year_of_Study) giống train_by_year\n",
        "\n",
        "try:\n",
        "    _ = PTXT_TOP\n",
        "except NameError:\n",
        "    PTXT_TOP = []\n",
        "PTXT_TOP_Y2PLUS = []\n",
        "\n",
        "# Tính features đầy đủ từ combined_cleaned\n",
        "if combined_cleaned is not None:\n",
        "    print('Tính features đầy đủ từ final_combined_cleaned (Y2+ dùng create_features_y2plus)...')\n",
        "    combined_feats = create_features_y2plus(combined_cleaned.copy())\n",
        "    if 'Year_of_Study' not in combined_feats.columns:\n",
        "        combined_feats['_year_start'] = combined_feats['Nam_Hoc'].str.split('-').str[0].astype(float)\n",
        "        combined_feats['Year_of_Study'] = (combined_feats['_year_start'] - combined_feats['NAM_TUYENSINH'] + 1).clip(lower=1).fillna(1).astype(int)\n",
        "        combined_feats = combined_feats.drop(columns=['_year_start'], errors='ignore')\n",
        "    train_mask = (\n",
        "        ((combined_feats['Nam_Hoc'] >= '2020-2021') & (combined_feats['Nam_Hoc'] < '2023-2024')) |\n",
        "        ((combined_feats['Nam_Hoc'] == '2023-2024') & (combined_feats['Hoc_Ky'] == 1))\n",
        "    )\n",
        "    valid_mask = (combined_feats['Nam_Hoc'] == '2023-2024') & (combined_feats['Hoc_Ky'] == 2)\n",
        "    train_feats_all = combined_feats[train_mask].copy()\n",
        "    valid_feats_all = combined_feats[valid_mask].copy()\n",
        "    # PTXT_GROUP Y2+: giữ TOP từ train Y2+, còn lại gán '1' (đồng dạng Y1)\n",
        "    if 'PTXT_GROUP' in train_feats_all.columns:\n",
        "        ptxt_counts_y2p = train_feats_all['PTXT_GROUP'].astype(str).value_counts()\n",
        "        PTXT_TOP_Y2PLUS = ptxt_counts_y2p.head(10).index.tolist()\n",
        "        for _df in [train_feats_all, valid_feats_all]:\n",
        "            _df.loc[~_df['PTXT_GROUP'].isin(PTXT_TOP_Y2PLUS), 'PTXT_GROUP'] = '1'\n",
        "        print(f'  PTXT_TOP Y2+ (10 giá trị phổ biến): {PTXT_TOP_Y2PLUS}')\n",
        "    print(f'  Train features: {len(train_feats_all)} rows | Valid features: {len(valid_feats_all)} rows')\n",
        "else:\n",
        "    train_feats_all = None\n",
        "    valid_feats_all = None\n",
        "    PTXT_TOP_Y2PLUS = []\n",
        "\n",
        "# Test Y2+: một file gộp (giống train_by_year) — dùng test_con_lai.csv, create_features một lần, lưu 1 file có Year_of_Study\n",
        "test_y2plus_feats_path = os.path.join(DATA_DIR, 'test_Y2plus_features.csv')\n",
        "if test_con_lai_df is not None and combined_cleaned is not None:\n",
        "    test_y2plus_raw = test_con_lai_df.copy()\n",
        "    for col in ['CPA', 'GPA', 'TC_HOANTHANH']:\n",
        "        if col not in test_y2plus_raw.columns:\n",
        "            test_y2plus_raw[col] = np.nan\n",
        "    if 'Nam_Hoc' not in test_y2plus_raw.columns and 'HOC_KY' in test_y2plus_raw.columns:\n",
        "        test_y2plus_raw['Nam_Hoc'] = test_y2plus_raw['HOC_KY'].astype(str).str.split().str[-1]\n",
        "    if 'Hoc_Ky' not in test_y2plus_raw.columns and 'HOC_KY' in test_y2plus_raw.columns:\n",
        "        test_y2plus_raw['Hoc_Ky'] = np.where(test_y2plus_raw['HOC_KY'].astype(str).str.contains('HK1'), 1, 2)\n",
        "    if 'Year_of_Study' not in test_y2plus_raw.columns:\n",
        "        _ys = test_y2plus_raw['Nam_Hoc'].astype(str).str.split('-').str[0].astype(float)\n",
        "        test_y2plus_raw['Year_of_Study'] = (_ys - pd.to_numeric(test_y2plus_raw['NAM_TUYENSINH'], errors='coerce') + 1).clip(lower=1).fillna(1).astype(int)\n",
        "    test_y2plus_raw['__is_test__'] = 1\n",
        "    base = combined_cleaned.copy()\n",
        "    base['__is_test__'] = 0\n",
        "    combined_plus = pd.concat([base, test_y2plus_raw], ignore_index=True, sort=False)\n",
        "    combined_plus_feats = create_features_y2plus(combined_plus)\n",
        "    if 'Year_of_Study' not in combined_plus_feats.columns:\n",
        "        _ys = combined_plus_feats['Nam_Hoc'].astype(str).str.split('-').str[0].astype(float)\n",
        "        combined_plus_feats['Year_of_Study'] = (_ys - combined_plus_feats['NAM_TUYENSINH'] + 1).clip(lower=1).fillna(1).astype(int)\n",
        "    tt = combined_plus_feats[combined_plus_feats['__is_test__'] == 1].copy()\n",
        "    tt = tt.drop(columns=['__is_test__'], errors='ignore')\n",
        "    if PTXT_TOP_Y2PLUS and 'PTXT_GROUP' in tt.columns:\n",
        "        tt.loc[~tt['PTXT_GROUP'].isin(PTXT_TOP_Y2PLUS), 'PTXT_GROUP'] = '1'\n",
        "    cols = [c for c in FEAT_COLS_Y2PLUS if c in tt.columns]\n",
        "    out_cols = ['MA_SO_SV', 'Year_of_Study'] + cols\n",
        "    tt[out_cols].to_csv(test_y2plus_feats_path, index=False)\n",
        "    print(f'  Test Y2+ (1 file gộp): {test_y2plus_feats_path} ({len(tt)} rows)')\n",
        "\n",
        "for year in range(2, 8):\n",
        "    key_train = f'Y{year}'\n",
        "    key_test = f'Y{year}' if year <= 7 else None\n",
        "    \n",
        "    train_final = None\n",
        "    \n",
        "    # Train: filter từ train_feats_all theo Year_of_Study\n",
        "    if train_feats_all is not None and 'Year_of_Study' in train_feats_all.columns:\n",
        "        tr = train_feats_all[train_feats_all['Year_of_Study'] == year].copy()\n",
        "        if len(tr) > 0:\n",
        "            cols = [c for c in FEAT_COLS_Y2PLUS if c in tr.columns]\n",
        "            train_final = tr[['MA_SO_SV'] + cols].copy()\n",
        "    elif key_train in train_files:\n",
        "        # Fallback: tính từ train_files riêng lẻ (có thể thiếu Prev_GPA/Prev_CPA)\n",
        "        tr = create_features_y2plus(train_files[key_train].copy())\n",
        "        cols = [c for c in FEAT_COLS_Y2PLUS if c in tr.columns]\n",
        "        train_final = tr[['MA_SO_SV'] + cols].copy()\n",
        "    \n",
        "    if train_final is not None:\n",
        "        p = os.path.join(DATA_DIR, f'train_Y{year}_features.csv')\n",
        "        train_final.to_csv(p, index=False)\n",
        "        print(f'Y{year} train: {p} ({len(train_final)} rows)')\n",
        "    if train_final is None:\n",
        "        print(f'Y{year}: không có dữ liệu')\n",
        "\n",
        "# Valid: tách riêng Y1 (feature khác Y2+) và Y2+ gộp một file\n",
        "# Valid Y1: valid_Y1_features.csv (MA_SO_SV + FEATS_Y1 + TC_DANGKY + TC_HOANTHANH) — Y1 không có cột Ratio, training sẽ tính từ TC_*\n",
        "if valid_y1_final is not None and 'Y1' in valid_files:\n",
        "    y1_df = valid_files['Y1'].set_index('MA_SO_SV')\n",
        "    y1_rows = y1_df.loc[valid_y1_final['MA_SO_SV']]\n",
        "    valid_y1_out = valid_y1_final.copy()\n",
        "    valid_y1_out['TC_DANGKY'] = y1_rows['TC_DANGKY'].values\n",
        "    valid_y1_out['TC_HOANTHANH'] = y1_rows['TC_HOANTHANH'].values\n",
        "    p_y1 = os.path.join(DATA_DIR, 'valid_Y1_features.csv')\n",
        "    valid_y1_out.to_csv(p_y1, index=False)\n",
        "    print(f'Valid Y1: {p_y1} ({len(valid_y1_out)} rows)')\n",
        "# Valid Y2+: valid_Y2plus_features.csv (MA_SO_SV + Year_of_Study + FEAT_COLS_Y2PLUS + Ratio + TC_HOANTHANH)\n",
        "if valid_feats_all is not None and 'Year_of_Study' in valid_feats_all.columns:\n",
        "    vd = valid_feats_all[valid_feats_all['Year_of_Study'] >= 2].copy()\n",
        "    if len(vd) > 0:\n",
        "        tc_dk = vd['TC_DANGKY'].replace(0, np.nan)\n",
        "        vd['Ratio'] = np.clip((vd['TC_HOANTHANH'] / tc_dk).fillna(0), 0, 1)\n",
        "        cols = [c for c in FEAT_COLS_Y2PLUS if c in vd.columns]\n",
        "        valid_y2p = vd[['MA_SO_SV', 'Year_of_Study'] + cols + ['Ratio', 'TC_DANGKY', 'TC_HOANTHANH']].copy()\n",
        "        p_y2p = os.path.join(DATA_DIR, 'valid_Y2plus_features.csv')\n",
        "        valid_y2p.to_csv(p_y2p, index=False)\n",
        "        print(f'Valid Y2+ (1 file): {p_y2p} ({len(valid_y2p)} rows)')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
